{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_tutorial_part2.ipynb","provenance":[],"collapsed_sections":["k3BmrwsIQEJ5"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zdxdC-sru6M3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287213827,"user_tz":-180,"elapsed":5623,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"279dced0-3423-47fc-ab73-6924e79bc2dd"},"source":["import torch\n","import torch.nn as nn\n","import torch.utils.data as torch_data\n","import torch.optim as optim\n","import numpy as np\n","import nltk\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"zW22e5KhQEJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287226319,"user_tz":-180,"elapsed":7247,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"4d9d2c9e-1b54-49ab-bb75-cca60e2c6793"},"source":["!git clone https://github.com/nvanva/filimdb_evaluation.git\n","!cd filimdb_evaluation; bash ./init.sh; cd .."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'filimdb_evaluation'...\n","remote: Enumerating objects: 126, done.\u001b[K\n","remote: Counting objects: 100% (126/126), done.\u001b[K\n","remote: Compressing objects: 100% (85/85), done.\u001b[K\n","remote: Total 503 (delta 71), reused 85 (delta 40), pack-reused 377\u001b[K\n","Receiving objects: 100% (503/503), 119.53 MiB | 53.21 MiB/s, done.\n","Resolving deltas: 100% (263/263), done.\n","train.tsv\n","dev.tsv\n","train_small.tsv\n","dev_small.tsv\n","test.tsv\n","FILIMDB/\n","FILIMDB/train.labels\n","FILIMDB/train_unlabeled.texts\n","FILIMDB/test.texts\n","FILIMDB/train.texts\n","FILIMDB/dev.labels\n","FILIMDB/dev.texts\n","FILIMDB/dev-b.labels\n","FILIMDB/dev-b.texts\n","FILIMDB/test-b.texts\n","PTB/ptb.train.txt\n","PTB/\n","PTB/README\n","PTB/ptb.test.txt\n","PTB/ptb.valid.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B8_bBsCrQEJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287226727,"user_tz":-180,"elapsed":2821,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"04e8bbb1-8d61-4d0e-c1b2-e974b68272a0"},"source":["from filimdb_evaluation.score import load_dataset_fast\n","datasets = load_dataset_fast(data_dir='./filimdb_evaluation/FILIMDB/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Loading train set \n","pos 7520\n","neg 7480\n","Loading dev set \n","pos 4980\n","neg 5020\n","Loading test set \n","unlabeled 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SwnQ6NyLQEJ3","executionInfo":{"status":"ok","timestamp":1607287231523,"user_tz":-180,"elapsed":799,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["def loadPart(datasets, part):\n","    texts = []\n","    labels = []\n","    for i in range(len(datasets[part][1])):\n","        tokens = [w.lower() for w in nltk.word_tokenize(datasets[part][1][i])]\n","        labels.append(1 if datasets[part][2][i]=='pos' else 0)\n","        texts.append(tokens)\n","    return texts, labels"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUs1RsgzQEJ3","executionInfo":{"status":"ok","timestamp":1607287270573,"user_tz":-180,"elapsed":39450,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["texts_train, labels_train = loadPart(datasets, 'train')\n","texts_val, labels_val = loadPart(datasets, 'dev')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"AND_qZQqQEJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287270869,"user_tz":-180,"elapsed":38180,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"e1730534-4d65-4482-a3e7-e5b3abddb110"},"source":["vocab = set()\n","for text in texts_train:\n","    vocab |= set(text)\n","len(vocab)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["88616"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"cTGi3fKzQEJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287716753,"user_tz":-180,"elapsed":483601,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"7b7b0505-2a7b-4644-a898-ff4d8f1863da"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip ./glove.6B.zip\n","w2ids = {}\n","ids = 1\n","w2ids[\"<pad>\"] = 0 # Special <pad> token to make all examples of equal length inside each batch.\n","vecs = [torch.zeros((1, 200), requires_grad=True)]\n","with open('glove.6B.200d.txt', encoding='utf-8') as f:\n","    for line in f:\n","        parts = line.strip().split()\n","        word = parts[0]\n","        if(word in vocab):\n","            vec = torch.tensor([float(num) for num in parts[1:]], requires_grad = True).view(1,-1)\n","            w2ids[word] = ids\n","            ids += 1\n","            vecs.append(vec)\n","vecs = torch.cat(vecs, dim=0)\n","vecs.shape"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2020-12-06 20:41:10--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2020-12-06 20:41:10--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2020-12-06 20:41:11--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  1.52MB/s    in 6m 46s  \n","\n","2020-12-06 20:47:57 (2.02 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  ./glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([54913, 200])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"WN8Lp5jr-kOK","executionInfo":{"status":"ok","timestamp":1607287814490,"user_tz":-180,"elapsed":677,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["# фиксируем гиперпараметры обучения нашей модели.\n","train_epoches = 10\n","learning_rate = 1e-3\n","batch_size = 20\n","gradient_accumulation_steps = 2\n","final_learning_rate = 1e-5 "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zYV6m1PWIFtE"},"source":["## Препроцессинг данных"]},{"cell_type":"markdown","metadata":{"id":"s40958z9IV80"},"source":["Удобно оформлять ввиде класса наследника torch.utils.data.Dataset, потому что в pytorch уже реализованы такие частые операции, как: перемешивание данных, разбиение на батчи, приведение к формату torch tensor. Причем есть возможность делать это параллельно. "]},{"cell_type":"code","metadata":{"id":"G8HVOiqwuRBk","executionInfo":{"status":"ok","timestamp":1607287817722,"user_tz":-180,"elapsed":749,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["#Чтобы представить данные в нужном формате надо перегрузить следующие методы, \n","#суть которых понятна из названия. \n","class ImdbData(torch_data.Dataset):\n","    def __init__(self, X, y, w2ids, aug):\n","        #инициализируем базовый класс\n","        super(ImdbData, self).__init__()\n","        self.X = X\n","        self.y = y\n","        self.w2i = w2ids\n","        self.aug = aug\n","    \n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx):\n","        tokens = self.X[idx]\n","        \n","        if(self.aug):\n","            half = len(tokens)//2\n","            if(np.random.binomial(1, 0.5)==1):\n","                tokens = tokens[:half]\n","            else:\n","                tokens = tokens[half:]\n","                \n","        ids = [self.w2i[t] for t in tokens if t in self.w2i]\n","        return (ids, self.y[idx])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eOr6tLCyQEJ3"},"source":["### Dataloader\n","-dataset (Dataset) – Датасет  \n","\n","-batch_size (python:int, optional) – Размер батча  \n","\n","-shuffle (bool, optional) – Перемешивать ли данные на каждой эпохе обучения.  \n","\n","-sampler (Sampler, optional) – определяет стратегию сэмплирования данных(shuffle=False)  \n","\n","-batch_sampler (Sampler, optional) – определяет стратегию сэмплирования батчей.  \n","\n","-num_workers (python:int, optional) – количество процессов в которых будет происходить формирвание батчей.  \n","\n","-collate_fn (callable, optional) – собирает список примеров в минибатчи.  \n","\n","-pin_memory (bool, optional) – копирование тензоров в бласть памяти из которой дальнейшая загрузка на гпу будет быстрее.   \n","\n","-drop_last (bool, optional) – выбрасывать ли последний батч в случае, если он меньше остальных  \n","\n","-timeout (numeric, optional) – ограничение по времени на формирование батча    "]},{"cell_type":"markdown","metadata":{"id":"62rDb9p-QC2-"},"source":["Сформируем итераторы по батчам из наших данных. Укажем размер батча, нужно ли данные перемешивать и количество потоков, которые будут формировать батчи. Параллелизм может ускорить формирование батча."]},{"cell_type":"code","metadata":{"id":"K5FYZ2w-QEJ4","executionInfo":{"status":"ok","timestamp":1607287820608,"user_tz":-180,"elapsed":665,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["# This function will make a batch (an input and a target tensor) from a list of examples.\n","# To make these tensors, we add <pad> tokens to each examples to make them all the same length.\n","def collate_fn(batch_list):\n","    max_len = max([len(sample[0]) for sample in batch_list])\n","    \n","    tokens_tensor = [sample[0]+[0]*(max_len-len(sample[0])) for sample in batch_list]\n","    tokens_tensor = torch.tensor(tokens_tensor, requires_grad=False, dtype = torch.int64)\n","    \n","    labels_tensor = [sample[1] for sample in batch_list]\n","    labels_tensor = torch.tensor(labels_tensor, requires_grad=False, dtype = torch.int64)\n","    \n","    return (tokens_tensor, labels_tensor)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"QB_B_Hqr4q9h","executionInfo":{"status":"ok","timestamp":1607287821787,"user_tz":-180,"elapsed":427,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["train_dataset = ImdbData(texts_train, labels_train, w2ids, aug = True)\n","val_dataset = ImdbData(texts_val, labels_val, w2ids, aug = False)\n","train_dataloader = torch_data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)\n","val_dataloader =  torch_data.DataLoader(val_dataset, batch_size= batch_size, shuffle=False, collate_fn = collate_fn)\n","#test_dataloader = torch_data.DataLoader(ImdbData(texts_test, labels_test, w2v), batch_size= batch_size, shuffle=False)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vRTJ7L_Oj6_8"},"source":["# Модель"]},{"cell_type":"code","metadata":{"id":"POL_tKwwQEJ4","executionInfo":{"status":"ok","timestamp":1607287823977,"user_tz":-180,"elapsed":643,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["def create_emb_layer(weights_matrix):\n","    num_embeddings, embedding_dim = weights_matrix.size()\n","    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n","    emb_layer.load_state_dict({'weight': weights_matrix})\n","    return emb_layer"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RClIZjC9R9vm"},"source":["Определим нашу модель как полносвязную нейронную сеть с двумя скрытыми слоями с функцией активации ReLU и dropout регуляризацией. В качестве входного представления текста будем использовать среднее арифметическое GLOVe  Также будем применять для регуляризации word dropout - каждый токен выкидывается из входного текста с вероятностью word_dropout.\n","\n","В общем случае для этого достаточно отнаследоваться от nn.Module и перегрузить следующие 2 метода.  \n","в \\_\\_init\\_\\_ вызываем конструкторы слоев с нужными гиперпараметрами.  \n","в forward применяем слои в нужном порядке. "]},{"cell_type":"code","metadata":{"id":"fHrEP4jGve3e","executionInfo":{"status":"ok","timestamp":1607287825161,"user_tz":-180,"elapsed":728,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["import torch.nn.functional as F\n","from torch.distributions.bernoulli import Bernoulli\n","\n","class Net(nn.Module):\n","    def __init__(self, vecs, word_dropout):\n","        super(Net, self).__init__()\n","        self.emb_layer = create_emb_layer(vecs)\n","        self.bern_sampler = Bernoulli(torch.tensor([1-word_dropout]))\n","        \n","        self.linear1 = nn.Linear(in_features=200, out_features=200)\n","        self.linear2 = nn.Linear(in_features=200, out_features=300)\n","        self.linear3 = nn.Linear(in_features=300, out_features=2) \n","        \n","        self.dropout1 = nn.Dropout(p=0.1, inplace=False)\n","        self.dropout2 = nn.Dropout(p=0.1, inplace=False)\n","        #self.matrix = nn.Parameter(torch.zeros((3,3), requires_grad=True))\n","\n","    def forward(self, tokens):\n","        pad_mask = (tokens != 0).unsqueeze(2)\n","        mask = pad_mask\n","        \n","        if(self.training):\n","            word_dropout_mask = self.bern_sampler.sample(sample_shape=torch.Size([tokens.shape[0], tokens.shape[1]]))\n","            word_dropout_mask = word_dropout_mask.to(mask.device)\n","            mask = mask*word_dropout_mask\n","        \n","        masked_inp  = (self.emb_layer(tokens)*mask)\n","        x = torch.mean(masked_inp, axis = 1)\n","        \n","        x = self.linear1(x)\n","        x = self.dropout1(x)\n","        x = F.relu(x)\n","        \n","        x = self.linear2(x)\n","        x = self.dropout2(x)\n","        x = F.relu(x)\n","        \n","        x = self.linear3(x)\n","        return x\n","model = Net(vecs, 0.2)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZouxVVbQEJ4","executionInfo":{"status":"ok","timestamp":1607287826018,"user_tz":-180,"elapsed":756,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["torch.nn.Module.__setattr__??"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tpwmQdsJTeUY"},"source":["Если же ваши вычисления придерживаются исключительно линейной логики, то код можно упростить с использованием Sequential"]},{"cell_type":"code","metadata":{"id":"tTsMMDdl0pfB","executionInfo":{"status":"ok","timestamp":1607285838274,"user_tz":-180,"elapsed":1506,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["#model = nn.Sequential(nn.Linear(in_features=200, out_features=200),\n","#                        nn.Dropout(p=0.1, inplace=False),\n","#                        nn.ReLU(),\n","#                        nn.Linear(in_features=200, out_features=2))"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRO2hojZW1KJ"},"source":["Определим можно ли проводить вычисления на GPU.  Если у вас несколько GPU, то в качестве device можно просто указать ее номер."]},{"cell_type":"code","metadata":{"id":"ciFDk1QR6Vbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287835648,"user_tz":-180,"elapsed":902,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"807fb726-c580-4a57-86d8-94bf4450eb13"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('Working on', device)\n","print('For faster training ensure that a cuda (GPU) device is used, not cpu!')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Working on cuda\n","For faster training ensure that a cuda (GPU) device is used, not cpu!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-GLy4u52XgXf"},"source":["Вычисления происходят там, где расположены ваши тензоры. Этой командой мы перемещаем параметры модели на нужный девайс."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37BwCCYQByA7","executionInfo":{"status":"ok","timestamp":1607287848666,"user_tz":-180,"elapsed":11054,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"2f82c9f9-bfe6-4758-b166-3b708bf8d624"},"source":["model.to(device)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (emb_layer): Embedding(54913, 200)\n","  (linear1): Linear(in_features=200, out_features=200, bias=True)\n","  (linear2): Linear(in_features=200, out_features=300, bias=True)\n","  (linear3): Linear(in_features=300, out_features=2, bias=True)\n","  (dropout1): Dropout(p=0.1, inplace=False)\n","  (dropout2): Dropout(p=0.1, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"ZgxdEW1cYrvN"},"source":["Передаем параметры модели в оптимизатор. Как вы видели ранее, тензоры сохраняют в себе градиенты. Оптимизатор достает их и применяет в соответствие с алгоритмом оптимизации."]},{"cell_type":"code","metadata":{"id":"koNmdCoe2EKR","executionInfo":{"status":"ok","timestamp":1607287848668,"user_tz":-180,"elapsed":9179,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6yNdO2IzY1Kw"},"source":["Зададим убывание learning rate. При каждом вызове метода step в ExponentialLR scheduler происходит домножение learning rate на параметр gamma. Будем делать scheduler step в конце каждой эпохи. Мы хотим чтобы за train_epoches шагов learning rate уменьшился до final_learning_rate. Из простой математики следует формула для gamma"]},{"cell_type":"code","metadata":{"id":"KenPwk931NaI","executionInfo":{"status":"ok","timestamp":1607287848669,"user_tz":-180,"elapsed":8868,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = (final_learning_rate/learning_rate)**(1/train_epoches))"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLKdRAJma0Dq"},"source":["CrossEntropyLoss по сути последовательное применение сначала softmax к логитам, потом logloss. Мы могли бы применить эти операции и сами, но их композиция, а главное градиенты по их композиции могут вычисляться оптимальнее."]},{"cell_type":"code","metadata":{"id":"dFaOvcA84zlv","executionInfo":{"status":"ok","timestamp":1607287848670,"user_tz":-180,"elapsed":8595,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["loss_function = torch.nn.CrossEntropyLoss(weight=None, reduction='mean')"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MU2DENlCQEJ4"},"source":["логгирование"]},{"cell_type":"code","metadata":{"id":"J6XJrPupQEJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287852247,"user_tz":-180,"elapsed":11332,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"12599c9f-f7a1-4897-f2f2-2fc6746a1b20"},"source":["#from torch.utils.tensorboard import SummaryWriter\n","!pip install tensorboardX\n","from tensorboardX import SummaryWriter\n","writer = SummaryWriter('./logs/')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\r\u001b[K     |█                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 26.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 31.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 31.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 33.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 27.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 25.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 24.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jp--tRaskMPj"},"source":["# Обучение"]},{"cell_type":"code","metadata":{"id":"sVDGM0Ie5Xo5","executionInfo":{"status":"ok","timestamp":1607287852250,"user_tz":-180,"elapsed":8597,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["#цикл обучения одной эпохи\n","step = 0\n","def trainOneEpoch(model, device, train_loader, \n","                  loss_function, optimizer, scheduler, writer, \n","                  gradient_accumulation_steps):\n","    global step\n","    # Есть слои, которые при обучении и при тестировании ведут себя по разному\n","    # Например таким слоем является dropout слой. Вызовом этого метода мы меняем поведение слоев на то,\n","    # которое должно быть при обучении.\n","    model.train()\n","    #для агрегации функции потерь по батчам.\n","    losses = []\n","    for i, (X, y) in enumerate(train_loader):\n","        # тензоры параметров модели уже находятся на нужном для вычисления устройстве. Переместим туда же данные.\n","        X, y = X.to(device), y.to(device)\n","        # выходы модели подадим в функцию потерь \n","        output = model(X) #model.forward()\n","        loss = loss_function(output, y)\n","        # При вызове backward() вычисленный градиент по каждому тензору прибавляются к полю тензора, накапливающему градиент по этому тензору. \n","        # Следующий командой вы обнуляете это поле.\n","        # Если вызывать обнуление не перед каждым шагом, то можно реализовать аккамулирование градиентов.\n","        # Это бывает полезно, если вы хотите использовать большой рамер батча, но на него не хватает памяти GPU. \n","        if gradient_accumulation_steps > 1:\n","            loss = loss / gradient_accumulation_steps\n","        # вычисление градиентов, прибавление к переменным аккамуляторам. \n","        loss.backward()\n","        \n","        #применяем вычисленные градиенты согласно нашему алгоритму оптимизации.\n","        if((i+1)%gradient_accumulation_steps==0):\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        #этой комндой мы получем numpy представление тензора. И залогируем его\n","        writer.add_scalar(\"train loss\", loss.item(), step)\n","        step += 1\n","    scheduler.step()"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsdQhiipQEJ4"},"source":["## forward vs __call__  \n","Управлять значениями параметров и градиентами вы можете через непосредственно тензоры и поле grad. Управлять входами и выходами слоев и градиентами по входам и выходам вы можете через hooks. Некоторые сложные слои могут использовать hooks в  своей реализации. \\_\\_call\\_\\_ заботится о hooks. Поэтому его вызов предпочтительнее."]},{"cell_type":"code","metadata":{"id":"cJ7uFMUKQEJ4","executionInfo":{"status":"ok","timestamp":1607287852252,"user_tz":-180,"elapsed":7611,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["model.__call__??"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPS7bRyE78y0","executionInfo":{"status":"ok","timestamp":1607287852297,"user_tz":-180,"elapsed":7395,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}}},"source":["def evalModel(model, test_loader, batch_size, device, loss_function):\n","    model.eval()\n","    S = 0\n","    S_loss = 0\n","    num_samples = 0\n","    num_batches = 0\n","    for X,y in test_loader:\n","        X, y = X.to(device), y.to(device)\n","        output = model(X)\n","        S_loss += loss_function(output, y).item()\n","        S+=torch.sum(torch.argmax(output, axis=1) != y).item()\n","        num_samples += X.shape[0]\n","        num_batches += 1\n","    return (S/num_samples, S_loss/num_batches) "],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8xhnaV3_uzZ","executionInfo":{"status":"ok","timestamp":1607287919552,"user_tz":-180,"elapsed":74368,"user":{"displayName":"ezhick ezhovsky","photoUrl":"","userId":"11850054778486990277"}},"outputId":"4139f934-0d22-46d5-9960-7eb714464f27"},"source":["from matplotlib import pyplot as plt\n","for epoch in range(train_epoches):\n","    trainOneEpoch(model, \n","                 device, \n","                 train_dataloader, \n","                 loss_function, \n","                 optimizer, \n","                 scheduler, writer, gradient_accumulation_steps)\n","    \n","    \n","    val_acc, val_loss = evalModel(model, val_dataloader, \n","                                                batch_size, device, loss_function)\n","    \n","    train_acc, train_loss = evalModel(model, train_dataloader, \n","                                                batch_size, device, loss_function)\n","    \n","    writer.add_scalar(\"val accuracy\", val_acc, epoch)\n","    \n","    writer.add_scalar(\"train accuracy\", train_acc, epoch)\n","    \n","    writer.add_scalar(\"val loss\", val_loss, epoch)\n","    \n","    print('Train/valid ERR: %.3f/%.3f Train/valid loss: %.5f/%.5f' % (train_acc, val_acc, train_loss, val_loss))\n","\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Train/valid ERR: 0.172/0.158 Train/valid loss: 0.39360/0.36844\n","Train/valid ERR: 0.131/0.125 Train/valid loss: 0.32166/0.31668\n","Train/valid ERR: 0.115/0.115 Train/valid loss: 0.28386/0.28676\n","Train/valid ERR: 0.108/0.113 Train/valid loss: 0.26672/0.27788\n","Train/valid ERR: 0.100/0.110 Train/valid loss: 0.24954/0.27044\n","Train/valid ERR: 0.096/0.109 Train/valid loss: 0.24228/0.26852\n","Train/valid ERR: 0.093/0.109 Train/valid loss: 0.23543/0.26703\n","Train/valid ERR: 0.093/0.108 Train/valid loss: 0.23690/0.26506\n","Train/valid ERR: 0.095/0.108 Train/valid loss: 0.23775/0.26456\n","Train/valid ERR: 0.087/0.107 Train/valid loss: 0.22624/0.26435\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pzVU4aMpQEJ5"},"source":["#!tensorboard --logdir ./logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3y53sCmBht5"},"source":["#Померяем error rate на тесте\n","#evalModel(model, test_dataloader, batch_size, device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"soJ7zKwgfO-n"},"source":["# Поговорим еще немного о тензорах"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VK7Dvq3pQEJ5"},"source":["Variable - в старых версиях для этих объектов отслеживалась история изменений. \n","Variable.data способ получить тензор лежащий внутри Variable.   \n","В более поздних версиях тензор смешали с Variable, но в библиотеке эти методы остались для совместимости.\n","Вместо .data лучше использовать detach()"]},{"cell_type":"markdown","metadata":{"id":"k3BmrwsIQEJ5"},"source":["### view vs reshape\n","Возврщает тензор с теми же данными, но другой формы. "]},{"cell_type":"code","metadata":{"id":"SC1cWVo_QEJ5","outputId":"909c96e8-25b7-42df-c299-c85d055ab7ef"},"source":["A = torch.arange(9)\n","B = A.view((3,3))\n","B[0,0]=100\n","A"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([100,   1,   2,   3,   4,   5,   6,   7,   8])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"Zxzvk4XiQEJ5"},"source":["reshape по возможности делает также, но может вернуть и копию. Поэтому в работе reshape есть некоторая неопределенность, которую надо учитывать.\n","Зато reshape умеет работать с non-contiguous тензорами."]},{"cell_type":"markdown","metadata":{"id":"8Hej1VLxQEJ5"},"source":["contiguous tensor тензор который хранится в непрерывном участке памяти. В следствие транспонирований или взятия среза результирующий тензор вполне может утрать это свойтво."]},{"cell_type":"code","metadata":{"id":"GLYndGzMQEJ5","outputId":"c137fe35-0965-4454-8799-21c435b93ab1"},"source":["x=np.arange(12).reshape(3,4).copy()\n","x.flags"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  C_CONTIGUOUS : True\n","  F_CONTIGUOUS : False\n","  OWNDATA : True\n","  WRITEABLE : True\n","  ALIGNED : True\n","  WRITEBACKIFCOPY : False\n","  UPDATEIFCOPY : False"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"ahLApalRQEJ5","outputId":"5fd45313-4c84-4da9-b379-d0256be58a88"},"source":["x.T.flags"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  C_CONTIGUOUS : False\n","  F_CONTIGUOUS : True\n","  OWNDATA : False\n","  WRITEABLE : True\n","  ALIGNED : True\n","  WRITEBACKIFCOPY : False\n","  UPDATEIFCOPY : False"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"PtvLMxq5QEJ5"},"source":[""],"execution_count":null,"outputs":[]}]}