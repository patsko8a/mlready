Список вопросов к экзамену (осень 2022) -- курс Арефьева Николая Викторовича

 1 Text classification. Bag of words / bag of n-grams representations. Zipf’s law. 
 2 Naive Bayes classifier: multinomial and bernoulli models. Laplace (alpha) smoothing.
 3 Linear regression. Perceptron.
 4 Logistic regression. Cross entropy loss. Multiclass/multilabel classification.
 5 Gradient descent. Full-batch versus stochastic gradient descent. Initialization and update rule for LR/FFNN.
 6 Feed-forward (fully connected) NN. Activation functions. NN as universal function approximator. Initialization and SGD update rule.
 7 Backpropagation. Derivation of gradients and weights update rule for binary/multiclass FFNN classifier with 1 hidden layer / K hidden layers.
 8 Training NNs with SGD: problems and solutions. Exponentially weighted average. Momentum, Adagrad, RMSProp, Adam.
 9 Classifier quality evaluation, surrogate loss functions. Expected versus empirical risk.
 10 Capacity / effective capacity of ML algorithm. Regularization. Generalization error decomposition. Bias/Variance tradeoff.
 11 Hyperparameter selection. Train/dev/test split. Cross Validation.
 12 Language models. Perplexity. Recurrent language model. 

 13 Vanishing/exploding gradient problem. LSTM. Gradient clipping.



Примеры дополнительных вопросов (validation set)

Некоторые примеры дополнительных вопросов. Приводится лишь небольшая часть вопросов - рекомендуем использовать их в качестве валидационной выборки для самопроверки, чтобы избежать переобучения.
0) Определение градиента функции. Геометрический смысл градиента. Найти градиент функции x**2 + 2 * y**2, изобразить линии уровня этой функции и траекторию градиентного спуска.
1) Почему нельзя инициализировать веса FFNN единицами? Что будет, если инициализировать их слишком большими / маленькими числами и почему? (требуется выписать формулы обновления весов и показать в них соответствующие проблемы)
2) Почему SGD плохо работает в ситуации, когда разные признаки имеют сильно отличающийся диапазон значений?
3) Из каких соображений выбираются распределения для инициализации весов сетей? (вывести параметры распределений)
4) Почему линейная регрессия плохо подходит для классификации?
5) Почему для логистической регрессии используется кросс-энтропия в качестве функции потерь?
6) Проблема затухания градиента в рекуррентных сетях - градиент по каким параметрам затухает, почему и при каких условиях, к каким именно проблемам это приводит?
7) Рекуррентная языковая модель: выписать формулы прямого прохода для входа "I love", указать размерности всех векторов и матриц в формулах, пояснить стоящую за формулами интуицию. 
8) В чем отличия в формулах прямого прохода рекуррентных ячеек LSTM и Vanilla RNN? Как это помогает уменьшить проблему затухания градиента? Почему это не решает проблему затухания градиента полностью?



Запись лекций: https://www.youtube.com/playlist?list=PLxEQA5k0LBt6PAORtrBl9EzXeY8fguS2M
